{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe1b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Assignment –Lab:\n",
    "o\tImplement the main steps of a Shallow Neural Network\n",
    "•\tUnderstand the dataset\n",
    "•\tImplement your first Forward and Backward propagation\n",
    "•\tImplement activation function, gradient descent\n",
    "•\tBuild Neural Network Model\n",
    "•\tTest and optimize the model\n",
    "•\tMake Predictions\n",
    "(to be done in Jupyter notebook. Need Jupyter-notebook and libraries installed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a2bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11eef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assignment –Lab:\n",
    "o\tPlotting Sigmoid 2D\n",
    "o\tPlotting Sigmoid 3D\n",
    "o\tContour Plot\n",
    "o\tPlotting Loss\n",
    "o\tStandardization\n",
    "o\tTest/Train split\n",
    "\n",
    "\n",
    "Assignment –Lab:\n",
    "o\tImplement the main steps of a Shallow Neural Network\n",
    "•\tUnderstand the dataset\n",
    "•\tImplement your first Forward and Backward propagation\n",
    "•\tImplement activation function, gradient descent\n",
    "•\tBuild Neural Network Model\n",
    "•\tTest and optimize the model\n",
    "•\tMake Predictions\n",
    "(to be done in Jupyter notebook. Need Jupyter-notebook and libraries installed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assignment –Lab 1:\n",
    "o\tImplement the main steps of a Shallow Neural Network\n",
    "•\tUnderstand the dataset\n",
    "•\tImplement your first Forward and Backward propagation\n",
    "•\tImplement activation function, gradient descent\n",
    "•\tBuild Neural Network Model\n",
    "•\tTest and optimize the model\n",
    "•\tMake Predictions\n",
    "(to be done in Jupyter notebook. Need Jupyter-notebook and libraries installed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39c62b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "92f4de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e038cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=df.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f54ab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2efc486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf53f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b58d792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test=x_train/255,x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "acd0ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "                                  tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                  tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "                                  tf.keras.layers.Dropout(0.2),\n",
    "                                  tf.keras.layers.Dense(10,activation=\"softmax\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "067d3f16",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword argument(s) in `compile()`: ({'metric'},). Valid keyword arguments include \"cloning\", \"experimental_run_tf_function\", \"distribute\", \"target_tensors\", or \"sample_weight_mode\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20696/2313667133.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.compile(optimizer=\"adam\",\n\u001b[0m\u001b[0;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m               metric=[\"accuracy\"])\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_validate_compile\u001b[1;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[0;32m   3075\u001b[0m     \u001b[0minvalid_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'sample_weight_mode'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3076\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minvalid_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3077\u001b[1;33m       raise TypeError('Invalid keyword argument(s) in `compile()`: '\n\u001b[0m\u001b[0;32m   3078\u001b[0m                       \u001b[1;34mf'{(invalid_kwargs,)}. Valid keyword arguments include '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m                       \u001b[1;34m'\"cloning\", \"experimental_run_tf_function\", \"distribute\",'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid keyword argument(s) in `compile()`: ({'metric'},). Valid keyword arguments include \"cloning\", \"experimental_run_tf_function\", \"distribute\", \"target_tensors\", or \"sample_weight_mode\"."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metric=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8547a8be",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20696/3104373177.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3158\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3160\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   3161\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "61e08649",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20696/132869415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3158\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3160\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   3161\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23adb9a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_20696/613822707.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_20696/613822707.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Assignment 2–Lab:\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Assignment 2–Lab:\n",
    "o\tPlotting Sigmoid 2D\n",
    "o\tPlotting Sigmoid 3D\n",
    "o\tContour Plot\n",
    "o\tPlotting Loss\n",
    "o\tStandardization\n",
    "o\tTest/Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c99c7e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches train=938, test=157\n"
     ]
    }
   ],
   "source": [
    "# creating the image data generator to standardize images\n",
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "\t\t\t\t\t\t\tfeaturewise_std_normalization=True)\n",
    "\n",
    "# calculating the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "\n",
    "# preparing iterators to scale images\n",
    "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
    "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
    "print('Batches train=%d, test=%d' % (len(train_iterator),\n",
    "\t\t\t\t\t\t\t\t\tlen(test_iterator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "109d17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting input to hidden weights: \n",
      "[[0.77132064 0.02075195 0.63364823 0.74880388]\n",
      " [0.49850701 0.22479665 0.19806286 0.76053071]\n",
      " [0.16911084 0.08833981 0.68535982 0.95339335]]\n",
      "Random starting hidden to output weights: \n",
      "[[0.00394827]\n",
      " [0.51219226]\n",
      " [0.81262096]\n",
      " [0.61252607]]\n",
      "The final prediction from neural network are: \n",
      "[[0.00572029]\n",
      " [0.99442052]\n",
      " [0.99527493]\n",
      " [0.00467507]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        np.random.seed(10) # for generating the same results\n",
    "        self.wij   = np.random.rand(3,4) # input to hidden layer weights\n",
    "        self.wjk   = np.random.rand(4,1) # hidden layer to output weights\n",
    "        \n",
    "    def sigmoid(self, x, w):\n",
    "        z = np.dot(x, w)\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoid_derivative(self, x, w):\n",
    "        return self.sigmoid(x, w) * (1 - self.sigmoid(x, w))\n",
    "    \n",
    "    def gradient_descent(self, x, y, iterations):\n",
    "        for i in range(iterations):\n",
    "            Xi = x\n",
    "            Xj = self.sigmoid(Xi, self.wij)\n",
    "            yhat = self.sigmoid(Xj, self.wjk)\n",
    "            # gradients for hidden to output weights\n",
    "            g_wjk = np.dot(Xj.T, (y - yhat) * self.sigmoid_derivative(Xj, self.wjk))\n",
    "            # gradients for input to hidden weights\n",
    "            g_wij = np.dot(Xi.T, np.dot((y - yhat) * self.sigmoid_derivative(Xj, self.wjk), self.wjk.T) * self.sigmoid_derivative(Xi, self.wij))\n",
    "            # update weights\n",
    "            self.wij += g_wij\n",
    "            self.wjk += g_wjk\n",
    "        print('The final prediction from neural network are: ')\n",
    "        print(yhat)\n",
    "if __name__ == '__main__':\n",
    "    neural_network = NeuralNetwork()\n",
    "    print('Random starting input to hidden weights: ')\n",
    "    print(neural_network.wij)\n",
    "    print('Random starting hidden to output weights: ')\n",
    "    print(neural_network.wjk)\n",
    "    X = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "    y = np.array([[0, 1, 1, 0]]).T\n",
    "    neural_network.gradient_descent(X, y, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5824ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Assignment –Lab:\n",
    "o\tImplement a two-class neural network with a hidden layer\n",
    "o\tImplement forward and backward propagation\n",
    "o\tCompute the cross-entropy loss\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde8929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
