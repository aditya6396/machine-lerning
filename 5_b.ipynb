{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c492b3",
   "metadata": {},
   "source": [
    ". Compute performance metrics for the given data 5_b.csv\n",
    "   Note 1: in this data you can see number of positive points << number of negatives points\n",
    "   Note 2: use pandas or numpy to read the data from 5_b.csv\n",
    "   Note 3: you need to derive the class labels from given score\n",
    "\n",
    " Compute Confusion Matrix \n",
    "\n",
    " Compute F1 Score \n",
    "\n",
    " Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) https://stackoverflow.com/q/53603376/4084039, https://stackoverflow.com/a/39678975/4084039\n",
    "\n",
    " Compute Accuracy Score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec8baefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64e9b1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba\n",
       "0  0.0  0.281035\n",
       "1  0.0  0.465152\n",
       "2  0.0  0.352793\n",
       "3  0.0  0.157818\n",
       "4  0.0  0.276648"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code\n",
    "data2 = pd.read_csv(\"5_b.csv\")\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be9d19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed3a9d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba  y_pred\n",
       "0  0.0  0.281035       0\n",
       "1  0.0  0.465152       0\n",
       "2  0.0  0.352793       0\n",
       "3  0.0  0.157818       0\n",
       "4  0.0  0.276648       0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Derive the class labels from given score\n",
    "f = lambda x: 0 if x < 0.5 else 1\n",
    "data2['y_pred'] = data2['proba'].map(f)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89b7efb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive points:  100\n",
      "Negative points:  10000\n"
     ]
    }
   ],
   "source": [
    "positive = 0\n",
    "negative = 0\n",
    "for i in range(0, len(data2)):\n",
    "    if data2['y'].loc[i] == 1:\n",
    "        positive += 1\n",
    "    elif data2['y'].loc[i] == 0:\n",
    "        negative += 1\n",
    "        \n",
    "print(\"Positive points: \", positive)\n",
    "print(\"Negative points: \", negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6a10c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[9761   45]\n",
      " [ 239   55]]\n"
     ]
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "\n",
    "confusion_matrix = []\n",
    "TN = int(data2[(data2.y == 0) & (data2.y_pred == 0)].count()[0])\n",
    "FN = int(data2[(data2.y == 1) & (data2.y_pred == 0)].count()[0])\n",
    "FP = int(data2[(data2.y == 0) & (data2.y_pred == 1)].count()[0])\n",
    "TP = int(data2[(data2.y == 1) & (data2.y_pred == 1)].count()[0])\n",
    "\n",
    "confusion_matrix.append(TN)\n",
    "confusion_matrix.append(FN)\n",
    "confusion_matrix.append(FP)\n",
    "confusion_matrix.append(TP)\n",
    "\n",
    "X = np.reshape(confusion_matrix, (2, 2))\n",
    "print(\"Confusion Matrix:\") \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd68b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "# Compute F1-Score\n",
    "# To compute the F1-Score, calculate Precision and Recall\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Recall = TP / (FN + TP)\n",
    "\n",
    "F1_score = 2 * Precision * Recall / (Precision + Recall)\n",
    "print(\"F1_score: \", F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86f2bd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "# Compute Accuracy\n",
    "accuracy = (TN + TP) / (TN + FN + FP + TP)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7baa47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score : 0.9377570000000001\n"
     ]
    }
   ],
   "source": [
    "# Compute AUC score\n",
    "data2 = data2.sort_values(by=['proba'], ascending=False)\n",
    "probabiltiy_score = data2['proba'].unique()\n",
    "y = data2['y'].to_numpy()\n",
    "plotting_data = []\n",
    "for threshold in probabiltiy_score:\n",
    "    threshold_y_pred = np.where(probabiltiy_score >= threshold, 1, 0)\n",
    "    nTP = (np.logical_and(y == 1.0, threshold_y_pred == 1)).sum()\n",
    "    nFN = (np.logical_and(y == 1.0, threshold_y_pred == 0)).sum()\n",
    "    nFP = (np.logical_and(y == 0.0, threshold_y_pred == 1)).sum()\n",
    "    nTN = (np.logical_and(y == 0.0, threshold_y_pred == 0)).sum()\n",
    "    TPR = nTP/(nTP + nFN)\n",
    "    FPR = nFP / (nTN + nFP)\n",
    "    plotting_data.append([TPR, FPR])\n",
    "\n",
    "plot_df = pd.DataFrame(data=plotting_data, columns=['TPR', 'FPR'])\n",
    "tpr_array = np.array([i for i, _ in plotting_data])\n",
    "fpr_array = np.array([i for _, i in plotting_data])\n",
    "auc_score = np.trapz(tpr_array, fpr_array)\n",
    "print('AUC score :', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d90c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204365d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
